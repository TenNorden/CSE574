{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Testing Datasets in CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#encode data to binary with 10 bits\n",
    "def encodeData(data):\n",
    "    \n",
    "    processedData = []\n",
    "    \n",
    "    for dataInstance in data:\n",
    "        \n",
    "        # Why do we have number 10? \n",
    "        #number of bit for 1000 in binary is 10. Turning inputs into a vector of activations. \n",
    "        # converting to binary: We get more number of input neurons by converting to binary\n",
    "        #>> moves binary bits of datainstance one to the right, & performs logical AND with binary of 1 and outputs binary\n",
    "        processedData.append([dataInstance >> d & 1 for d in range(10)])\n",
    "    \n",
    "    #returns an array of processed data in binaries of 10 bits\n",
    "    return np.array(processedData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1026, 10)\n",
      "[['0359a' '2' '1' '1' '0' '2' '2' '0' '2' '2']\n",
      " ['0577a' '2' '1' '1' '0' '2' '2' '0' '1' '2']\n",
      " ['1120a' '2' '1' '1' '3' '2' '2' '0' '2' '2']\n",
      " ['1120b' '1' '1' '1' '0' '2' '2' '0' '2' '2']\n",
      " ['1120c' '2' '1' '1' '0' '2' '2' '0' '0' '2']\n",
      " ['1121a' '2' '1' '1' '3' '2' '2' '0' '1' '2']\n",
      " ['1121b' '2' '1' '1' '0' '2' '2' '0' '3' '2']\n",
      " ['1121c' '1' '1' '1' '0' '2' '2' '0' '1' '2']\n",
      " ['1229b' '1' '1' '1' '3' '2' '2' '0' '2' '2']\n",
      " ['1302a' '2' '1' '1' '3' '2' '2' '0' '0' '2']]\n",
      "['0359a' '0359b' '1']\n"
     ]
    }
   ],
   "source": [
    "# get data from .csv file and parse them \n",
    "#filename = filename.csv\n",
    "def get_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        dat = csv.reader(f, delimiter = ',')\n",
    "        #get column name from first row\n",
    "        col_name = next(dat)\n",
    "        #get all the rows as a list\n",
    "        data = list(dat)\n",
    "        #return data as numpy array\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "#Processing Dataset # concatenation of paired up img_ids\n",
    "# args: data: humanobserved-features , # pair: list of same or diff pairs. \n",
    "def process_data(data, pair, x):\n",
    "    \n",
    "    features = []\n",
    "    target = []\n",
    "    for i in range(len(pair)):\n",
    "        for j in range(len(data)):\n",
    "            if pair[i][x] == data[j][0]:\n",
    "                f = (data[j][1:]) \n",
    "                features.append(f)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def getTarget(pair):\n",
    "    return  np.array([pair[t][-1] for t in range(len(pair))]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = get_data('HumanObserved-Features-Data.csv')\n",
    "dat = np.array([data[d][1:] for d in range(len(data))])\n",
    "diff_pair = get_data('diffn_pairs.csv')\n",
    "same_pair = get_data('same_pairs.csv')\n",
    "\n",
    "print(dat.shape)\n",
    "#print(d_pair.shape)\n",
    "#print(s_pair.shape)\n",
    "print(dat[:10])\n",
    "print(same_pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(data, pair, operation):\n",
    "    img1 = np.array(process_data(data, pair, x = 0)).astype(float)\n",
    "    img2 = np.array(process_data(data, pair, x = 1)).astype(float)\n",
    "    if operation == 'concatenate':\n",
    "        feature = np.array(np.concatenate((img1, img2), axis = 1))\n",
    "        \n",
    "    elif operation =='subtract':\n",
    "        feature = np.abs(np.array(img1 - img2))\n",
    "        \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get target\n",
    "Target_same = getTarget(same_pair)\n",
    "Target_diff = getTarget(diff_pair)\n",
    "print(Target_same.shape)\n",
    "print(Target_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get concatenate and subtrated features for same and different pairs\n",
    "same_sub = getData(dat, same_pair, operation = 'subtract')\n",
    "same_conc = getData(dat, same_pair, operation = 'concatenate')\n",
    "diff_sub = getData(dat, diff_pair, operation = 'subtract')\n",
    "diff_conc = getData(dat, diff_pair, operation = 'concatenate')\n",
    "print(same_sub[1])\n",
    "print(same_conc[1])\n",
    "print(diff_conc.shape)\n",
    "print(diff_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add target to concatenated feature dataset\n",
    "same_conc_t = np.c_[same_conc, Target_same]\n",
    "diff_conc_t = np.c_[diff_conc, Target_diff]\n",
    "\n",
    "diff_conc_t = np.array(diff_conc_t[:791])\n",
    "print(same_conc_t.shape)\n",
    "print(diff_conc_t.shape)\n",
    "\n",
    "\n",
    "# add target to subtracted feature dataset\n",
    "same_sub_t = np.c_[same_sub, Target_same]\n",
    "diff_sub_t = np.c_[diff_sub, Target_diff]\n",
    "diff_sub_t = np.array(diff_sub_t[:791])\n",
    "print(same_sub_t.shape)\n",
    "print(diff_sub_t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791,)\n",
      "(293032,)\n",
      "(791, 19)\n",
      "(791, 19)\n"
     ]
    }
   ],
   "source": [
    "# Read Dataset using pandas\n",
    "\n",
    "\n",
    "# get target\n",
    "Target_same = getTarget(same_pair)\n",
    "Target_diff = getTarget(diff_pair)\n",
    "print(Target_same.shape)\n",
    "print(Target_diff.shape)\n",
    "\n",
    "\n",
    "same_conc = pd.read_csv('same_conc.csv', delimiter = ',', header = None).values\n",
    "diff_conc  = pd.read_csv('diff_conc.csv', delimiter = ',', header = None).values\n",
    "\n",
    "\n",
    "# add target to concatenated feature dataset\n",
    "same_conc_t = np.c_[same_conc, Target_same]\n",
    "diff_conc_t = np.c_[diff_conc, Target_diff]\n",
    "\n",
    "diff_conc_t = np.array(diff_conc_t[:791])\n",
    "print(same_conc_t.shape)\n",
    "print(diff_conc_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 19)\n",
      "[[2. 2. 1. 3. 2. 2. 0. 1. 1. 1. 1. 1. 0. 0. 3. 1. 2. 1. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 1. 0. 1. 0.]]\n",
      "(1582,)\n",
      "(1582, 18)\n"
     ]
    }
   ],
   "source": [
    "#1. human observed feature concatenated # concatenate same and diff pairs matrices and shuffle them\n",
    "h_obs_conc = np.concatenate((same_conc_t, diff_conc_t), axis = 0)\n",
    "np.random.shuffle(h_obs_conc)  # randomly shuffle same and diff pairs\n",
    "\n",
    "print(h_obs_conc.shape)\n",
    "print(h_obs_conc[:2]) # print first five rows of the parsed data\n",
    "\n",
    "Target_conc = h_obs_conc[:, -1]\n",
    "print(Target_conc.shape)\n",
    "\n",
    "#get concatenated matrix after shuffling diff and same pairs\n",
    "\n",
    "feature_conc = h_obs_conc[:,:-1]  \n",
    "print(feature_conc.shape)\n",
    "t =int(0.9*len(feature_conc))\n",
    "TrainingData = feature_conc[:t]\n",
    "TestingData = feature_conc[t+1:]\n",
    "\n",
    "TrainingTarget = np.array(Target_conc[:t])\n",
    "TestingTarget = np.array(Target_conc[t+1:])\n",
    "\n",
    "TrainingTarget = np.array([[i] for i in TrainingTarget])\n",
    "TestingTarget = np.array([[i] for i in TestingTarget])\n",
    "\n",
    "# print(TrainingData.shape)\n",
    "\n",
    "# print(TestingData.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 1. 3. 2. 2. 0. 1. 1. 1. 1. 1. 0. 0. 3. 1. 2. 1. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 1. 0. 1. 0.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 3. 3. 2. 0.]\n",
      " [2. 1. 1. 3. 0. 2. 0. 1. 2. 1. 0. 1. 0. 2. 2. 0. 3. 2. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 1. 2. 3. 1. 3. 2. 0.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 3. 4. 2. 0.]\n",
      " [0. 0. 1. 3. 2. 2. 0. 0. 2. 1. 2. 1. 2. 2. 2. 1. 0. 1. 1.]\n",
      " [2. 0. 1. 0. 2. 1. 0. 0. 2. 2. 1. 1. 0. 2. 3. 1. 4. 2. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 1. 2. 0. 1. 1. 3. 2. 2. 0. 0. 2. 0.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 1. 2. 0. 1. 1. 0. 2. 2. 1. 2. 2. 0.]]\n",
      "[1. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "[[2. 2. 1. 3. 2. 2. 0. 1. 1. 1. 1. 1. 0. 0. 3. 1. 2. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 1. 0. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 3. 3. 2.]\n",
      " [2. 1. 1. 3. 0. 2. 0. 1. 2. 1. 0. 1. 0. 2. 2. 0. 3. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 1. 2. 3. 1. 3. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 3. 4. 2.]\n",
      " [0. 0. 1. 3. 2. 2. 0. 0. 2. 1. 2. 1. 2. 2. 2. 1. 0. 1.]\n",
      " [2. 0. 1. 0. 2. 1. 0. 0. 2. 2. 1. 1. 0. 2. 3. 1. 4. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 1. 2. 0. 1. 1. 3. 2. 2. 0. 0. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 1. 2. 0. 1. 1. 0. 2. 2. 1. 2. 2.]]\n",
      "[[2. 2. 1. 3. 2. 2. 0. 1. 1. 1. 1. 1. 0. 0. 3. 1. 2. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 1. 0. 1.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 3. 3. 2.]\n",
      " [2. 1. 1. 3. 0. 2. 0. 1. 2. 1. 0. 1. 0. 2. 2. 0. 3. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 1. 2. 3. 1. 3. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 2. 2. 2. 1. 1. 0. 2. 2. 3. 4. 2.]\n",
      " [0. 0. 1. 3. 2. 2. 0. 0. 2. 1. 2. 1. 2. 2. 2. 1. 0. 1.]\n",
      " [2. 0. 1. 0. 2. 1. 0. 0. 2. 2. 1. 1. 0. 2. 3. 1. 4. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 1. 2. 0. 1. 1. 3. 2. 2. 0. 0. 2.]\n",
      " [2. 1. 1. 0. 2. 2. 0. 1. 2. 0. 1. 1. 0. 2. 2. 1. 2. 2.]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(h_obs_conc[:10])\n",
    "print(Target_conc[:10])\n",
    "print(feature_conc[:10])\n",
    "print(TrainingData[:10])\n",
    "print(TrainingTarget[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining Placeholder\n",
    "inputTensor  = tf.placeholder(tf.float32, [None, 18]) #for 10bit input vector activations\n",
    "outputTensor = tf.placeholder(tf.float32, [None, 1])  #a bucket for 4 classes of output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network model for 2 hidden layer is defined \n",
    "\n",
    "NUM_HIDDEN_NEURONS_LAYER_1 = 100\n",
    "NUM_HIDDEN_NEURONS_LAYER_2 = 100\n",
    "\n",
    "\n",
    "# hyperparameter. change from 0.1 to 1 for this project\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Initializing the weights to Normal Distribution   (random values)\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev=0.01))\n",
    "\n",
    "# Initializing the input to hidden layer weights\n",
    "input_hidden_weights1  = init_weights([18, NUM_HIDDEN_NEURONS_LAYER_1])    \n",
    "\n",
    "\n",
    "#Initializing the input to hidden layer 2 weights\n",
    "input_hidden_weights2  = init_weights([NUM_HIDDEN_NEURONS_LAYER_1, NUM_HIDDEN_NEURONS_LAYER_2])\n",
    "\n",
    "\n",
    "# Initializing the hidden to output layer 2 weights\n",
    "hidden_output_weights2 = init_weights([NUM_HIDDEN_NEURONS_LAYER_2, 1])\n",
    "\n",
    "\n",
    "# Computing values at the hidden layer 1\n",
    "#Relu is applied on te sum of the product of the inputtensor and input_hidden_weights;  \n",
    "hidden_layer1 = tf.nn.relu(tf.matmul(inputTensor, input_hidden_weights1))  \n",
    "\n",
    "#computing values at 2nd hiddend layer\n",
    "hidden_layer2 = tf.nn.relu(tf.matmul(hidden_layer1, input_hidden_weights2))\n",
    "\n",
    "\n",
    "\n",
    "# Computing values at the output layer\n",
    "#output of hidden layer is fed as input for the output layer and it is multiplied with weights\n",
    "output_layer = tf.matmul(hidden_layer2, hidden_output_weights2)\n",
    "\n",
    "\n",
    "# Defining Error Function # cost function. we need to minimize it  \n",
    "#softmax activation function for classification problem to compute probabilites for classes\n",
    "#cross_entropy error function as used for this classifier problem which makes backpropagation math easier\n",
    "error_function = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output_layer, labels=outputTensor))\n",
    "\n",
    "# Defining Learning Algorithm and Training Parameters\n",
    "# gradientdescent optimizer is used to minimize the error function. \n",
    "#set learning rate hyper parameter. determines the step of the gradient descent. \n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(error_function)  #optimizer, minimizing error\n",
    "\n",
    "# Prediction Function # prediction will be the largest output\n",
    "prediction = tf.round(tf.sigmoid(output_layer))\n",
    "#prediction = output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eced7acd22f4715af51907a6a61bd4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-4e67995611df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             sess.run(training, feed_dict={inputTensor: processedTrainingData[start:end], \n\u001b[0;32m---> 25\u001b[0;31m                                           outputTensor: processedTraininglabel[start:end]})            \n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Training accuracy for an epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         training_accuracy.append(np.mean((processedTraininglabel) ==\n",
      "\u001b[0;32m/Users/TenzinNorden/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TenzinNorden/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TenzinNorden/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TenzinNorden/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TenzinNorden/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TenzinNorden/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_OF_EPOCHS = 5000  #number of forward and backward propagation of the full training data\n",
    "BATCH_SIZE = 100  #number of training data set in one forward and backward propagation \n",
    "\n",
    "training_accuracy = []\n",
    "output = []\n",
    "\n",
    "# A tensorflow session is set to run the tensorflow model graph above. \n",
    "with tf.Session() as sess:  \n",
    "    \n",
    "    # Set Global Variables ?\n",
    "    #Initialize all the variables (weights) at once. \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(NUM_OF_EPOCHS)):\n",
    "        \n",
    "        #Shuffle the Training Dataset at each epoch\n",
    "        p = np.random.permutation(range(len(TrainingData)))\n",
    "        processedTrainingData  = TrainingData[p]\n",
    "        processedTraininglabel = TrainingTarget[p]\n",
    "        \n",
    "        # Start batch training  \n",
    "        for start in range(0, len(processedTrainingData), BATCH_SIZE):\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(training, feed_dict={inputTensor: processedTrainingData[start:end], \n",
    "                                          outputTensor: processedTraininglabel[start:end]})            \n",
    "        # Training accuracy for an epoch \n",
    "        training_accuracy.append(np.mean((processedTraininglabel) ==\n",
    "                                         sess.run(prediction, feed_dict={inputTensor: processedTrainingData,\n",
    "                                                             outputTensor: processedTraininglabel})))\n",
    "    # Testing : processedtesting data as input\n",
    "    predictedTestTarget = sess.run(prediction, feed_dict={inputTensor: TestingData})\n",
    "   # erroroutput = sess.run(error_function, feed_dict={inputTensor:processedTrainingData,\n",
    "#                                                      outputTensor: processedTrainingLabel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12835f048>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISAi4mP/H3EDqAEXs+vfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12accd588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pandas dataframe. plotting traning accuracy for every epochs. \n",
    "df = pd.DataFrame()\n",
    "df['acc'] = training_accuracy\n",
    "df.plot(grid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model [Software 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 6  Correct :152\n",
      "Testing Accuracy: 96.20253164556962\n"
     ]
    }
   ],
   "source": [
    "# finding the accuracy by comparing with the known testing labels.\n",
    "\n",
    "wrong   = 0\n",
    "right   = 0\n",
    "\n",
    "predictedTestTargetList = []\n",
    "\n",
    "for i,j in zip(TestingTarget,predictedTestTarget):\n",
    "\n",
    "    if i == j:\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "\n",
    "print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "print(\"Testing Accuracy: \" + str(right/(right+wrong)*100))\n",
    "\n",
    "# Please input your UBID and personNumber \n",
    "# testDataInput = testingData['input'].tolist()\n",
    "# testDataLabel = testingData['label'].tolist()\n",
    "\n",
    "# testDataInput.insert(0, \"tenzinno\")\n",
    "# testDataLabel.insert(0, \"50096989\")\n",
    "\n",
    "# testDataInput.insert(1, \"tenzinno\")\n",
    "# testDataLabel.insert(1, \"50096989\")\n",
    "\n",
    "# predictedTestLabelList.insert(0, \"\")\n",
    "# predictedTestLabelList.insert(1, \"\")\n",
    "\n",
    "# #create columns in pandas dataframe with column names input and label, with values test data and respective labels\n",
    "# output = {}\n",
    "# output[\"input\"] = testDataInput\n",
    "# output[\"label\"] = testDataLabel\n",
    "\n",
    "# # create column name predicted label with the predicted labels for the test data\n",
    "# output[\"predicted_label\"] = predictedTestLabelList\n",
    "\n",
    "# # create a csv output file of the pandas dataframe\n",
    "# opdf = pd.DataFrame(output)\n",
    "# opdf.to_csv('output2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
